{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vip\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [str(x) for x in Path('../prompts_dataset/').glob('*.txt')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train(files=paths, vocab_size=30_522, min_frequency=2, special_tokens= [\n",
    "    '<s>', '</s>', '<pad>', '<unk>', '<mask>', '<lvl1>', '</lvl1>', '<lvl2>', '</lvl2>', '<lvl3>', '</lvl3>'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neublla_codex\\\\vocab.json', 'neublla_codex\\\\merges.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_model('neublla_codex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Open', 'Ġword', 'Ġand', 'Ġs', 'e', 'arch', 'Ġabout', 'Ġp', 'al', 'a', 'st', 'ine']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\"Open word and search about palastine\").tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1172"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vip\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "token_embed = tf.keras.layers.Embedding(tokenizer.get_vocab_size(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one input sample text preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"Open Word and write in it summerization about palastine\"\n",
    "\n",
    "sample_text_encode = tokenizer.encode(sample_text)\n",
    "sample_text_tokens = sample_text_encode.tokens\n",
    "sample_text_tokens_ids = sample_text_encode.ids\n",
    "sample_text_tokens_seq = np.array(sample_text_tokens_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text encoding info\n",
      "Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "Sample text tokens\n",
      "['Open', 'Ġ', 'W', 'ord', 'Ġand', 'Ġwrite', 'Ġin', 'Ġit', 'Ġsum', 'm', 'er', 'iz', 'ation', 'Ġabout', 'Ġp', 'al', 'a', 'st', 'ine']\n",
      "Sample text tokens ids\n",
      "[312, 231, 65, 834, 276, 485, 316, 428, 327, 87, 299, 356, 340, 511, 281, 286, 75, 288, 345]\n",
      "Sample text tokens seq\n",
      "[312 231  65 834 276 485 316 428 327  87 299 356 340 511 281 286  75 288\n",
      " 345]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample text encoding info\")\n",
    "print(sample_text_encode)\n",
    "print(\"Sample text tokens\")\n",
    "print(sample_text_tokens)\n",
    "print(\"Sample text tokens ids\")\n",
    "print(sample_text_tokens_ids)\n",
    "print(\"Sample text tokens seq\")\n",
    "print(sample_text_tokens_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for the sample text :  Open Word and write in it summerization about palastine\n",
      "tf.Tensor(\n",
      "[[ 0.04135612 -0.00572587  0.03753925  0.03605526]\n",
      " [ 0.01498193  0.01342216  0.01358687 -0.03752574]\n",
      " [ 0.0326019  -0.00050863  0.01794283 -0.04231886]\n",
      " [ 0.04451884 -0.01857741 -0.04477407 -0.00033475]\n",
      " [ 0.04417815 -0.00697638 -0.0224834  -0.04487335]\n",
      " [ 0.04052586  0.04054067  0.04665941 -0.00291703]\n",
      " [-0.04508409  0.03455592  0.02227939 -0.00777333]\n",
      " [ 0.04890242 -0.03603184  0.00567744  0.016881  ]\n",
      " [-0.01856792  0.04017048 -0.01840692  0.04524991]\n",
      " [-0.04305512  0.01641395  0.01962784  0.04297377]\n",
      " [-0.0237705  -0.03859905 -0.0329558   0.04898859]\n",
      " [ 0.02387314 -0.03762925  0.00668324 -0.01946318]\n",
      " [ 0.00535963 -0.04968458  0.0174357   0.03351486]\n",
      " [ 0.00837679 -0.04752765 -0.04236186 -0.02681269]\n",
      " [ 0.04558358  0.03740418  0.044698   -0.03811712]\n",
      " [ 0.04007835  0.00682516 -0.03968145 -0.02213687]\n",
      " [ 0.02645295 -0.0049573  -0.03480594  0.01608089]\n",
      " [ 0.03688603 -0.04027524 -0.01531561 -0.00767209]\n",
      " [ 0.01558966  0.03189416  0.02867606 -0.02886891]], shape=(19, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "token_embed = tf.keras.layers.Embedding(tokenizer.get_vocab_size(), 4)\n",
    "token_embeddngs = token_embed(sample_text_tokens_seq)\n",
    "\n",
    "print(\"Embedding for the sample text : \", sample_text)\n",
    "print(token_embeddngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18], shape=(19,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "max_sequnce_length = 256\n",
    "positional_embedding = tf.keras.layers.Embedding(max_sequnce_length, 4)\n",
    "\n",
    "position_index = tf.range(len(sample_text_tokens_seq))\n",
    "print(position_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position embeddings for the input sequence \n",
      " tf.Tensor(\n",
      "[[-0.00544344 -0.02864941  0.02475016 -0.02316974]\n",
      " [-0.04755345 -0.01766795  0.02219016 -0.02556071]\n",
      " [ 0.01220468 -0.00049644  0.02757603  0.00976502]\n",
      " [-0.02611597 -0.00513328  0.03445197  0.00394219]\n",
      " [-0.03646388  0.01631213 -0.00366051 -0.04461161]\n",
      " [ 0.01634559 -0.01496141 -0.0442906  -0.03573897]\n",
      " [-0.0434481   0.0332484   0.04691509  0.03815332]\n",
      " [-0.01728294 -0.03424324 -0.00068649  0.00536634]\n",
      " [-0.04481184  0.00757898 -0.04713923  0.03090293]\n",
      " [ 0.04719767 -0.02100389  0.01492533  0.00744049]\n",
      " [ 0.03493549  0.01961224 -0.04319534 -0.0047025 ]\n",
      " [ 0.0470147   0.0156523  -0.01025097 -0.01084021]\n",
      " [-0.00425587 -0.02942917 -0.0305195   0.04409963]\n",
      " [-0.00424488 -0.03441774  0.04994818 -0.02517501]\n",
      " [ 0.03513424 -0.03474926  0.00937317  0.01592946]\n",
      " [-0.04132128 -0.02816194  0.01747085  0.02480358]\n",
      " [-0.01298972  0.01999925  0.02672352 -0.01542353]\n",
      " [ 0.03422523  0.01432257 -0.03386471  0.01039493]\n",
      " [-0.00597199  0.04958165  0.04588119 -0.01627157]], shape=(19, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "positional_embeddings = positional_embedding(position_index)\n",
    "print(\"Position embeddings for the input sequence \\n\", positional_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to the initial encoder block : \n",
      " tf.Tensor(\n",
      "[[ 0.03591268 -0.03437529  0.06228942  0.01288551]\n",
      " [-0.03257152 -0.00424579  0.03577703 -0.06308645]\n",
      " [ 0.04480659 -0.00100506  0.04551887 -0.03255384]\n",
      " [ 0.01840287 -0.02371069 -0.01032209  0.00360744]\n",
      " [ 0.00771428  0.00933575 -0.02614391 -0.08948496]\n",
      " [ 0.05687145  0.02557926  0.00236881 -0.038656  ]\n",
      " [-0.08853219  0.06780431  0.06919448  0.03038   ]\n",
      " [ 0.03161948 -0.07027508  0.00499095  0.02224734]\n",
      " [-0.06337976  0.04774946 -0.06554614  0.07615285]\n",
      " [ 0.00414255 -0.00458994  0.03455316  0.05041425]\n",
      " [ 0.01116499 -0.01898681 -0.07615115  0.04428609]\n",
      " [ 0.07088784 -0.02197694 -0.00356773 -0.0303034 ]\n",
      " [ 0.00110376 -0.07911376 -0.0130838   0.07761449]\n",
      " [ 0.00413191 -0.08194539  0.00758633 -0.0519877 ]\n",
      " [ 0.08071782  0.00265492  0.05407117 -0.02218766]\n",
      " [-0.00124292 -0.02133678 -0.0222106   0.00266672]\n",
      " [ 0.01346323  0.01504196 -0.00808243  0.00065736]\n",
      " [ 0.07111125 -0.02595267 -0.04918033  0.00272284]\n",
      " [ 0.00961767  0.08147581  0.07455724 -0.04514048]], shape=(19, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input = token_embeddngs + positional_embeddings\n",
    "print(\"Input to the initial encoder block : \\n\", input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch input preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching\n",
    "input_batch = [\n",
    "    'Open Word and save it in \"Home directory\" as \"my_word_file\"',\n",
    "    'Connect the wifi to \"Aizen-sama\" network',\n",
    "    'Search about palastine new today and give me a summary about it'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized inputs : \n",
      "\n",
      "[[312, 231, 65, 834, 276, 1011, 428, 316, 231, 12, 50, 858, 290, 83, 278, 366, 411, 12, 998, 231, 12, 87, 99, 73, 97, 834, 73, 80, 505, 12], [45, 269, 88, 529, 293, 317, 83, 80, 83, 342, 231, 12, 43, 356, 275, 23, 93, 75, 963, 12, 369, 347, 97, 477], [325, 511, 281, 286, 75, 288, 345, 464, 342, 78, 612, 276, 491, 83, 326, 463, 267, 354, 511, 428]]\n",
      "input to the encoder is : \n",
      "(3, 30)\n",
      "[[ 312  231   65  834  276 1011  428  316  231   12   50  858  290   83\n",
      "   278  366  411   12  998  231   12   87   99   73   97  834   73   80\n",
      "   505   12]\n",
      " [  45  269   88  529  293  317   83   80   83  342  231   12   43  356\n",
      "   275   23   93   75  963   12  369  347   97  477    0    0    0    0\n",
      "     0    0]\n",
      " [ 325  511  281  286   75  288  345  464  342   78  612  276  491   83\n",
      "   326  463  267  354  511  428    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n"
     ]
    }
   ],
   "source": [
    "# encode the bache\n",
    "input_batch_encodeing = tokenizer.encode_batch(input_batch)\n",
    "\n",
    "# input sequences\n",
    "input_seqs = []\n",
    "\n",
    "input_seqs.append(input_batch_encodeing[0].ids)\n",
    "input_seqs.append(input_batch_encodeing[1].ids)\n",
    "input_seqs.append(input_batch_encodeing[2].ids)\n",
    "\n",
    "print(\"Vectorized inputs : \\n\")\n",
    "print(input_seqs)\n",
    "\n",
    "# padding the inputs to be in the same length\n",
    "padded_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(input_seqs, padding=\"post\")\n",
    "print(\"input to the encoder is : \")\n",
    "print(padded_input_seqs.shape)\n",
    "print(padded_input_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded input : \n",
      "[[ 312  231   65  834  276 1011  428  316  231   12   50  858  290   83\n",
      "   278  366  411   12  998  231   12   87   99   73   97  834   73   80\n",
      "   505   12]\n",
      " [  45  269   88  529  293  317   83   80   83  342  231   12   43  356\n",
      "   275   23   93   75  963   12  369  347   97  477    0    0    0    0\n",
      "     0    0]\n",
      " [ 325  511  281  286   75  288  345  464  342   78  612  276  491   83\n",
      "   326  463  267  354  511  428    0    0    0    0    0    0    0    0\n",
      "     0    0]] \n",
      "\n",
      "Encoder mask : \n",
      "tf.Tensor(\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]], shape=(3, 30), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "encoder_mask = tf.cast(tf.math.not_equal(padded_input_seqs, 0), tf.float32)\n",
    "print('padded input : ')\n",
    "print(padded_input_seqs, '\\n')\n",
    "print(\"Encoder mask : \")\n",
    "print(encoder_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 30), dtype=float32, numpy=\n",
       "array([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expanded dimenstion of the mask\n",
    "encoder_mask = encoder_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "encoder_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Head Self-Attention\n",
    "\n",
    "Q => Queries <br>\n",
    "K => Keysz   <br>\n",
    "V => Values  <br>\n",
    "\n",
    "Attention (Q, K, V) = softmax( (Q* K**T) / (sqrt(dimension_of_K) ) ) * V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "\n",
    "    key_dimension = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    scaled_scores = tf.matmul(query, key, transpose_b=True) / np.sqrt(key_dimension)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_scores = tf.where(mask==0, -np.inf, scaled_scores)\n",
    "    \n",
    "    softmax = tf.keras.layers.Softmax()\n",
    "    weights = softmax(scaled_scores)\n",
    "\n",
    "    return tf.matmul(weights, value), weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing scaled_dot_product_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries:\n",
      " [[0.80500383 0.03377964 0.13195879 0.84726906]\n",
      " [0.45987372 0.72889927 0.28293487 0.38553415]\n",
      " [0.53535543 0.47184523 0.59735394 0.28063174]]\n"
     ]
    }
   ],
   "source": [
    "seq_len = 3\n",
    "embed_dim = 4\n",
    "\n",
    "queries = np.random.rand(seq_len, embed_dim)\n",
    "keys = np.random.rand(seq_len, embed_dim)\n",
    "values = np.random.rand(seq_len, embed_dim)\n",
    "\n",
    "print(\"Queries:\\n\", queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output\n",
      " tf.Tensor(\n",
      "[[0.5502248  0.72442263 0.8154087  0.63397896]\n",
      " [0.543003   0.70325315 0.8146995  0.6312506 ]\n",
      " [0.5385741  0.6985322  0.81817216 0.6330553 ]], shape=(3, 4), dtype=float32) \n",
      "\n",
      "Weights\n",
      " tf.Tensor(\n",
      "[[0.28666583 0.34785348 0.36548063]\n",
      " [0.2609815  0.38686407 0.3521544 ]\n",
      " [0.26998356 0.39809936 0.33191705]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "output, attn_weights = scaled_dot_product_attention(queries, keys, values)\n",
    "\n",
    "print(\"Output\\n\", output, \"\\n\")\n",
    "print(\"Weights\\n\", attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MHSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, dimension_model, num_heads):\n",
    "        super(MultHeadSelfAttention, self).__init__()\n",
    "        self.dimension_model = dimension_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.dimension_head = self.dimension_model // self.num_heads\n",
    "\n",
    "        self.query_weights = tf.keras.layers.Dense(self.dimension_model)\n",
    "        self.key_weights = tf.keras.layers.Dense(self.dimension_model)\n",
    "        self.value_weights = tf.keras.layers.Dense(self.dimension_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(self.dimension_model)\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        split_inputs = tf.reshape(x, (batch_size, -1, self.num_heads, self.dimension_head))\n",
    "        return tf.transpose(split_inputs, prem=[0, 2, 1, 3])\n",
    "    \n",
    "    def merge_heads(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        merge_inputs = tf.transpose(x, perm=[0, 2, 1 ,3])\n",
    "        return tf.reshape(merge_inputs, (batch_size, -1, self.dimension_model))\n",
    "    \n",
    "    def call(self, q, k, v, mask):\n",
    "        qs = self.query_weights(q)\n",
    "        ks = self.key_weights(k)\n",
    "        ws = self.value_weights(v)\n",
    "\n",
    "        output, attention_weights = scaled_dot_product_attention(qs, ks, ws, mask)\n",
    "        output = self.merge_heads(output)\n",
    "\n",
    "        return self.dense(output), attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing MHSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of each head: 4\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 3\n",
    "embed_dim = 12\n",
    "num_heads = 3\n",
    "head_dim = embed_dim // num_heads\n",
    "\n",
    "print(f\"Dimension of each head: {head_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (1, 3, 12) \n",
      "\n",
      "Input:\n",
      " [[[0.5 0.5 0.5 0.3 0.5 0.9 0.5 0.6 0.7 0.7 0.8 0.8]\n",
      "  [0.8 0.9 0.5 0.7 0.7 0.6 0.6 0.1 0.6 0.2 0.3 1. ]\n",
      "  [0.8 0.2 0.5 0.7 0.5 0.9 0.8 0.6 0.3 0.3 0.5 0.7]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(batch_size, seq_len, embed_dim).round(1)\n",
    "print(\"Input shape: \", x.shape, \"\\n\")\n",
    "print(\"Input:\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHSA output(1, 3, 12):\n",
      "tf.Tensor(\n",
      "[[[-1.2071465  -0.06055957  0.10553324  0.26423037 -0.31229752\n",
      "   -1.1887401  -0.05269921  0.3778549  -0.8093019  -0.63126004\n",
      "   -2.1432676   0.43046826]\n",
      "  [-1.2079288  -0.05357718  0.10137948  0.25435773 -0.30541348\n",
      "   -1.1914468  -0.04718618  0.36833608 -0.81488645 -0.6340164\n",
      "   -2.1403008   0.4294031 ]\n",
      "  [-1.2087305  -0.05903447  0.10013899  0.2558182  -0.30636075\n",
      "   -1.1827621  -0.04979318  0.37264413 -0.8032694  -0.63422287\n",
      "   -2.134417    0.42795324]]], shape=(1, 3, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mhsa = MultHeadSelfAttention(12, 3)\n",
    "\n",
    "output, attn_weights = mhsa(x, x, x, None)\n",
    "print(f\"MHSA output{output.shape}:\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward_network(dimension_model, hidden_dimension):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(hidden_dimension, activation='relu'),\n",
    "        tf.keras.layers.Dense(dimension_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, dimension_model, num_heads, hidden_dimension, dropout_rate=0.1):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "\n",
    "        self.mhsa = MultHeadSelfAttention(dimension_model, num_heads)\n",
    "        self.ffn = feed_forward_network(dimension_model, hidden_dimension)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization()\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization()\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        mhsa_output, attention_weights = self.mhsa(x, x, x, mask)\n",
    "        # drop out\n",
    "        mhsa_output = self.dropout1(mhsa_output, training=training)\n",
    "        # skip connection\n",
    "        mhsa_output = self.layernorm1(x + mhsa_output)\n",
    "\n",
    "        ffn_output = self.ffn(mhsa_output)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        output = self.layernorm2(mhsa_output + ffn_output)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_blocks, dimension_model, num_heads, hidden_dimension, src_vocab_size, max_seq_len, dropout_rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.dimension_model = dimension_model\n",
    "        self.max_sql_len = max_seq_len\n",
    "\n",
    "        self.token_embedding = tf.keras.layers.Embedding(src_vocab_size, self.dimension_model)\n",
    "        self.positonal_embedding = tf.keras.layers.Embedding(max_seq_len, self.dimension_model)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "        self.blocks = [EncoderBlock(self.dimension_model, num_heads, hidden_dimension, dropout_rate)\n",
    "                       for _ in range(num_blocks)]\n",
    "    \n",
    "    def call(self, input, training, mask):\n",
    "        token_embeddings = self.token_embedding(input)\n",
    "\n",
    "        num_pos = input.shape[0] * self.max_sql_len\n",
    "        positional_index = np.resize(np.arange(self.max_sql_len), num_pos)\n",
    "        positional_index = np.reshape(positional_index, input.shape)\n",
    "        positional_embeddings = self.positonal_embedding(positional_index)\n",
    "\n",
    "        x = self.dropout(token_embeddings + positional_embeddings, training=training)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x, weights = block(x, training, mask)\n",
    "        \n",
    "        return x, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks = 6\n",
    "\n",
    "dimension_model = 12\n",
    "\n",
    "num_heads = 3\n",
    "\n",
    "hidden_dimension = 48\n",
    "\n",
    "src_vocab_size = tokenizer.get_vocab_size()\n",
    "\n",
    "max_seq_len = padded_input_seqs.shape[1]\n",
    "\n",
    "encoder = Encoder(\n",
    "    num_blocks,\n",
    "    dimension_model,\n",
    "    num_heads,\n",
    "    hidden_dimension,\n",
    "    src_vocab_size,\n",
    "    max_seq_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vip\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\normalization\\layer_normalization.py:328: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Encoder Output (3, 30, 12):\n",
      "tf.Tensor(\n",
      "[[[ 0.86667323  0.6334505  -0.8810883  ...  1.5660397  -2.4376056\n",
      "   -0.45869628]\n",
      "  [ 1.3837068   0.93641776 -1.096625   ...  1.6101617  -0.43953797\n",
      "   -0.93298656]\n",
      "  [ 0.82491654  0.9677865  -1.3013407  ...  1.1717308  -1.8046833\n",
      "   -0.3565267 ]\n",
      "  ...\n",
      "  [ 0.83404845  0.8141851  -0.34106517 ...  1.6112067  -1.835874\n",
      "   -0.7375326 ]\n",
      "  [ 0.8244405   0.542211   -0.92117625 ...  1.5226535  -2.0762346\n",
      "   -1.09233   ]\n",
      "  [ 0.73770005  1.0138857  -1.0542717  ...  1.9158467  -1.9500427\n",
      "   -0.7627504 ]]\n",
      "\n",
      " [[-0.61692566  1.1565527   0.39518926 ... -0.9645132  -1.7991585\n",
      "   -0.6586123 ]\n",
      "  [-1.2369397   0.13564107  0.48053375 ...  0.3204566  -2.5138562\n",
      "   -0.43897542]\n",
      "  [-2.1387205   0.31437173 -0.26597062 ...  0.11428353 -1.1958406\n",
      "    0.14232978]\n",
      "  ...\n",
      "  [-0.66300243  1.5214471   0.23052539 ... -0.05507722 -1.3478061\n",
      "   -0.13909958]\n",
      "  [-0.3794233   1.2180223  -0.06938656 ...  0.9477912  -0.45573404\n",
      "   -1.1960592 ]\n",
      "  [-1.3385246   0.90298843 -0.12966353 ...  0.6782981  -1.5736188\n",
      "   -0.49750444]]\n",
      "\n",
      " [[ 1.0179791   0.6440683  -1.2254461  ...  1.2605782  -2.268605\n",
      "   -1.0619928 ]\n",
      "  [ 1.4932467   0.8082704  -0.961816   ...  1.4166667  -0.07971667\n",
      "   -0.4377757 ]\n",
      "  [ 1.1122414   1.1656128  -1.1197587  ...  1.475342   -1.8465631\n",
      "   -0.19475716]\n",
      "  ...\n",
      "  [ 0.43179443  1.1415466  -1.1399435  ...  1.3694909  -1.9248079\n",
      "   -0.87391365]\n",
      "  [ 0.8040915   1.1390584  -1.0215347  ...  1.5335983  -1.7272528\n",
      "   -1.089026  ]\n",
      "  [ 0.9531073   1.1756176  -1.1398679  ...  1.6236887  -1.7020383\n",
      "   -0.76297766]]], shape=(3, 30, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "encoder_output, attn_wieghts = encoder(input=padded_input_seqs, training=True, mask=encoder_mask)\n",
    "\n",
    "print(f\"Encoder Output {encoder_output.shape}:\")\n",
    "print(encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
