{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vip\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [str(x) for x in Path('../prompts_dataset/').glob('*.txt')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train(files=paths, vocab_size=30_522, min_frequency=2, special_tokens= [\n",
    "    '<s>', '</s>', '<pad>', '<unk>', '<mask>', '<lvl1>', '</lvl1>', '<lvl2>', '</lvl2>', '<lvl3>', '</lvl3>'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neublla_codex\\\\vocab.json', 'neublla_codex\\\\merges.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_model('neublla_codex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Open', 'Ġword', 'Ġand', 'Ġs', 'e', 'arch', 'Ġabout', 'Ġp', 'al', 'a', 'st', 'ine']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\"Open word and search about palastine\").tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1172"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vip\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "token_embed = tf.keras.layers.Embedding(tokenizer.get_vocab_size(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one input sample text preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"Open Word and write in it summerization about palastine\"\n",
    "\n",
    "sample_text_encode = tokenizer.encode(sample_text)\n",
    "sample_text_tokens = sample_text_encode.tokens\n",
    "sample_text_tokens_ids = sample_text_encode.ids\n",
    "sample_text_tokens_seq = np.array(sample_text_tokens_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text encoding info\n",
      "Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "Sample text tokens\n",
      "['Open', 'Ġ', 'W', 'ord', 'Ġand', 'Ġwrite', 'Ġin', 'Ġit', 'Ġsum', 'm', 'er', 'iz', 'ation', 'Ġabout', 'Ġp', 'al', 'a', 'st', 'ine']\n",
      "Sample text tokens ids\n",
      "[312, 231, 65, 834, 276, 485, 316, 428, 327, 87, 299, 356, 340, 511, 281, 286, 75, 288, 345]\n",
      "Sample text tokens seq\n",
      "[312 231  65 834 276 485 316 428 327  87 299 356 340 511 281 286  75 288\n",
      " 345]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample text encoding info\")\n",
    "print(sample_text_encode)\n",
    "print(\"Sample text tokens\")\n",
    "print(sample_text_tokens)\n",
    "print(\"Sample text tokens ids\")\n",
    "print(sample_text_tokens_ids)\n",
    "print(\"Sample text tokens seq\")\n",
    "print(sample_text_tokens_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for the sample text :  Open Word and write in it summerization about palastine\n",
      "tf.Tensor(\n",
      "[[-0.03630493  0.0274328  -0.00939428 -0.02420539]\n",
      " [ 0.01618392  0.02466606 -0.03620122  0.0063921 ]\n",
      " [ 0.02877239  0.03542027 -0.03710765 -0.032242  ]\n",
      " [-0.01899385  0.03584211  0.00212605 -0.04259966]\n",
      " [ 0.02594898  0.02037451 -0.0040069  -0.02101295]\n",
      " [ 0.01231384  0.02004592  0.02444588 -0.02153223]\n",
      " [-0.04819325  0.01104289  0.00707861  0.02770778]\n",
      " [ 0.01950746  0.04034619 -0.03092113 -0.02754783]\n",
      " [-0.03130431 -0.03454777 -0.00364064  0.02853609]\n",
      " [-0.00214807 -0.02208556  0.0242735   0.00072006]\n",
      " [ 0.0302528  -0.01662111  0.03619123  0.03471193]\n",
      " [-0.01913691 -0.03676101 -0.04960042 -0.02287838]\n",
      " [ 0.0084547  -0.01431551  0.00488999 -0.02975402]\n",
      " [ 0.0152544  -0.01315112  0.04092289  0.01256461]\n",
      " [-0.04864443 -0.0039563  -0.00519235  0.04519092]\n",
      " [-0.0271754   0.0185007   0.01124263  0.03897769]\n",
      " [-0.02620639 -0.03252237 -0.00217569  0.01760075]\n",
      " [-0.01326066 -0.04830096  0.02189927 -0.02675102]\n",
      " [ 0.01985974  0.04434115 -0.0162348  -0.01603328]], shape=(19, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "token_embed = tf.keras.layers.Embedding(tokenizer.get_vocab_size(), 4)\n",
    "token_embeddngs = token_embed(sample_text_tokens_seq)\n",
    "\n",
    "print(\"Embedding for the sample text : \", sample_text)\n",
    "print(token_embeddngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18], shape=(19,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "max_sequnce_length = 256\n",
    "positional_embedding = tf.keras.layers.Embedding(max_sequnce_length, 4)\n",
    "\n",
    "position_index = tf.range(len(sample_text_tokens_seq))\n",
    "print(position_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position embeddings for the input sequence \n",
      " tf.Tensor(\n",
      "[[-0.03884591 -0.01983836 -0.02478283 -0.0480801 ]\n",
      " [-0.04058124  0.04588704 -0.03497245 -0.00831879]\n",
      " [-0.0489208  -0.00684286 -0.03502395  0.02460959]\n",
      " [-0.00570335 -0.00302011  0.0182308   0.03927718]\n",
      " [-0.04746342 -0.01213201  0.01247581 -0.0020106 ]\n",
      " [ 0.04292064  0.00975777 -0.00591248  0.04649416]\n",
      " [ 0.03875117  0.01110225  0.04103955 -0.00164498]\n",
      " [ 0.01972629 -0.04984891  0.03763548  0.04384668]\n",
      " [ 0.021817   -0.0072284  -0.04759295 -0.02095134]\n",
      " [-0.03592795  0.04394368  0.02386128 -0.00324935]\n",
      " [ 0.01474606 -0.02054697  0.03108385 -0.03301616]\n",
      " [ 0.00983285  0.03703486  0.01827924 -0.0471835 ]\n",
      " [ 0.01684762  0.02001305 -0.03500403  0.01748348]\n",
      " [-0.00653331 -0.03454687  0.00137032  0.03025103]\n",
      " [-0.00987024  0.04271311  0.0376168  -0.01781525]\n",
      " [ 0.02537708  0.00454026  0.04553256  0.03755797]\n",
      " [-0.02649524 -0.02697958 -0.04152282 -0.01068585]\n",
      " [-0.00125985  0.01459514 -0.01035311 -0.00119312]\n",
      " [-0.039701    0.02395973  0.02283968  0.01023715]], shape=(19, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "positional_embeddings = positional_embedding(position_index)\n",
    "print(\"Position embeddings for the input sequence \\n\", positional_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to the initial encoder block : \n",
      " tf.Tensor(\n",
      "[[-0.07515083  0.00759445 -0.0341771  -0.07228549]\n",
      " [-0.02439732  0.0705531  -0.07117367 -0.00192669]\n",
      " [-0.02014841  0.0285774  -0.0721316  -0.00763241]\n",
      " [-0.02469721  0.032822    0.02035685 -0.00332247]\n",
      " [-0.02151444  0.0082425   0.00846891 -0.02302355]\n",
      " [ 0.05523448  0.02980369  0.0185334   0.02496193]\n",
      " [-0.00944208  0.02214514  0.04811816  0.0260628 ]\n",
      " [ 0.03923374 -0.00950272  0.00671435  0.01629885]\n",
      " [-0.00948731 -0.04177617 -0.05123359  0.00758475]\n",
      " [-0.03807602  0.02185812  0.04813478 -0.00252929]\n",
      " [ 0.04499886 -0.03716809  0.06727508  0.00169577]\n",
      " [-0.00930406  0.00027385 -0.03132118 -0.07006188]\n",
      " [ 0.02530232  0.00569754 -0.03011404 -0.01227054]\n",
      " [ 0.00872109 -0.04769799  0.04229321  0.04281564]\n",
      " [-0.05851468  0.03875681  0.03242445  0.02737566]\n",
      " [-0.00179832  0.02304096  0.05677519  0.07653566]\n",
      " [-0.05270163 -0.05950195 -0.04369851  0.0069149 ]\n",
      " [-0.01452051 -0.03370582  0.01154616 -0.02794413]\n",
      " [-0.01984125  0.06830088  0.00660487 -0.00579613]], shape=(19, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input = token_embeddngs + positional_embeddings\n",
    "print(\"Input to the initial encoder block : \\n\", input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch input preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching\n",
    "input_batch = [\n",
    "    'Open Word and save it in \"Home directory\" as \"my_word_file\"',\n",
    "    'Connect the wifi to \"Aizen-sama\" network',\n",
    "    'Search about palastine new today and give me a summary about it'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized inputs : \n",
      "\n",
      "[[312, 231, 65, 834, 276, 1011, 428, 316, 231, 12, 50, 858, 290, 83, 278, 366, 411, 12, 998, 231, 12, 87, 99, 73, 97, 834, 73, 80, 505, 12], [45, 269, 88, 529, 293, 317, 83, 80, 83, 342, 231, 12, 43, 356, 275, 23, 93, 75, 963, 12, 369, 347, 97, 477], [325, 511, 281, 286, 75, 288, 345, 464, 342, 78, 612, 276, 491, 83, 326, 463, 267, 354, 511, 428]]\n",
      "input to the encoder is : \n",
      "(3, 30)\n",
      "[[ 312  231   65  834  276 1011  428  316  231   12   50  858  290   83\n",
      "   278  366  411   12  998  231   12   87   99   73   97  834   73   80\n",
      "   505   12]\n",
      " [  45  269   88  529  293  317   83   80   83  342  231   12   43  356\n",
      "   275   23   93   75  963   12  369  347   97  477    0    0    0    0\n",
      "     0    0]\n",
      " [ 325  511  281  286   75  288  345  464  342   78  612  276  491   83\n",
      "   326  463  267  354  511  428    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n"
     ]
    }
   ],
   "source": [
    "# encode the bache\n",
    "input_batch_encodeing = tokenizer.encode_batch(input_batch)\n",
    "\n",
    "# input sequences\n",
    "input_seqs = []\n",
    "\n",
    "input_seqs.append(input_batch_encodeing[0].ids)\n",
    "input_seqs.append(input_batch_encodeing[1].ids)\n",
    "input_seqs.append(input_batch_encodeing[2].ids)\n",
    "\n",
    "print(\"Vectorized inputs : \\n\")\n",
    "print(input_seqs)\n",
    "\n",
    "# padding the inputs to be in the same length\n",
    "padded_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(input_seqs, padding=\"post\")\n",
    "print(\"input to the encoder is : \")\n",
    "print(padded_input_seqs.shape)\n",
    "print(padded_input_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded input : \n",
      "[[ 312  231   65  834  276 1011  428  316  231   12   50  858  290   83\n",
      "   278  366  411   12  998  231   12   87   99   73   97  834   73   80\n",
      "   505   12]\n",
      " [  45  269   88  529  293  317   83   80   83  342  231   12   43  356\n",
      "   275   23   93   75  963   12  369  347   97  477    0    0    0    0\n",
      "     0    0]\n",
      " [ 325  511  281  286   75  288  345  464  342   78  612  276  491   83\n",
      "   326  463  267  354  511  428    0    0    0    0    0    0    0    0\n",
      "     0    0]] \n",
      "\n",
      "Encoder mask : \n",
      "tf.Tensor(\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0.]], shape=(3, 30), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "encoder_mask = tf.cast(tf.math.not_equal(padded_input_seqs, 0), tf.float32)\n",
    "print('padded input : ')\n",
    "print(padded_input_seqs, '\\n')\n",
    "print(\"Encoder mask : \")\n",
    "print(encoder_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 30), dtype=float32, numpy=\n",
       "array([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expanded dimenstion of the mask\n",
    "encoder_mask = encoder_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "encoder_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Head Self-Attention\n",
    "\n",
    "Q => Queries <br>\n",
    "K => Keysz   <br>\n",
    "V => Values  <br>\n",
    "\n",
    "Attention (Q, K, V) = softmax( (Q* K**T) / (sqrt(dimension_of_K) ) ) * V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    key_dimension = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    scaled_scores = tf.matmul(query, key, transpose_b=True) / np.sqrt(key_dimension)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_scores = tf.where(mask==0, -np.inf, scaled_scores)\n",
    "    \n",
    "    softmax = tf.keras.layers.Softmax()\n",
    "    weights = softmax(scaled_scores)\n",
    "\n",
    "    return tf.matmul(weights, value), weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, dimension_model, num_heads):\n",
    "        super(MultHeadSelfAttention, self).__init__()\n",
    "        self.dimension_model = dimension_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.dimension_head = self.dimension_model // self.num_heads\n",
    "\n",
    "        self.query_weights = tf.keras.layers.Dense(self.dimension_model)\n",
    "        self.key_weights = tf.keras.layers.Dense(self.dimension_model)\n",
    "        self.value_weights = tf.keras.layers.Dense(self.dimension_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(self.dimension_model)\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        split_inputs = tf.reshape(x, (batch_size, -1, self.num_heads, self.dimension_head))\n",
    "        return tf.transpose(split_inputs, prem=[0, 2, 1, 3])\n",
    "    \n",
    "    def merge_heads(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        merge_inputs = tf.transpose(x, perm=[0, 2, 1 ,3])\n",
    "        return tf.reshape(merge_inputs, (batch_size, -1, self.dimension_model))\n",
    "    \n",
    "    def call(self, q, k, v, mask):\n",
    "        qs = self.query_weights(q)\n",
    "        ks = self.key_weights(k)\n",
    "        ws = self.value_weights(v)\n",
    "\n",
    "        output, attention_weights = scaled_dot_product_attention(qs, ks, ws, mask)\n",
    "        output = self.merge_heads(output)\n",
    "\n",
    "        return self.dense(output), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward_network(dimension_model, hidden_dimension):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(hidden_dimension, activation='relu'),\n",
    "        tf.keras.layers.Dense(dimension_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, dimension_model, num_heads, hidden_dimension, dropout_rate=0.1):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "\n",
    "        self.mhsa = MultHeadSelfAttention(dimension_model, num_heads)\n",
    "        self.ffn = feed_forward_network(dimension_model, hidden_dimension)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization()\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization()\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        mhsa_output, attention_weights = self.mhsa(x, x, x, mask)\n",
    "        # drop out\n",
    "        mhsa_output = self.dropout1(mhsa_output, training=training)\n",
    "        # skip connection\n",
    "        mhsa_output = self.layernorm1(x + mhsa_output)\n",
    "\n",
    "        ffn_output = self.ffn(mhsa_output)\n",
    "        ffn_output = self.dropout2(ffn_output, trainin=training)\n",
    "        output = self.layernorm2(mhsa_output + ffn_output)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_blocks, dimension_model, num_heads, hidden_dimension, src_vocab_size, max_seq_len, dropout_rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.dimension_model = dimension_model\n",
    "        self.max_sql_len = max_seq_len\n",
    "\n",
    "        self.token_embedding = tf.keras.layers.Embedding(src_vocab_size, self.dimension_model)\n",
    "        self.positonal_embedding = tf.keras.layers.Embedding(max_seq_len, self.dimension_model)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "        self.blocks = [EncoderBlock(self.dimension_model, num_heads, hidden_dimension, dropout_rate)\n",
    "                       for _ in range(num_blocks)]\n",
    "    \n",
    "    def call(self, input, training, mask):\n",
    "        token_embeddings = self.token_embedding(input)\n",
    "\n",
    "        num_pos = input.shape[0] * self.max_sql_len\n",
    "        positional_index = np.resize(np.arange(self.max_sql_len), num_pos)\n",
    "        positional_index = np.reshape(positional_index, input.shape)\n",
    "        positional_embeddings = self.positonal_embedding(positional_index)\n",
    "\n",
    "        x = self.dropout(token_embeddings + positional_embeddings, training=training)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x, weights = block(x, training, mask)\n",
    "        \n",
    "        return x, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\"><h3>declaring an encoder</h3></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks = 6\n",
    "\n",
    "dimension_model = 12\n",
    "\n",
    "num_heads = 3\n",
    "\n",
    "hidden_dimension = 48\n",
    "\n",
    "src_vocab_size = tokenizer.get_vocab_size()\n",
    "\n",
    "max_seq_len = padded_input_seqs.shape[1]\n",
    "\n",
    "encoder = Encoder(\n",
    "    num_blocks,\n",
    "    dimension_model,\n",
    "    num_heads,\n",
    "    hidden_dimension,\n",
    "    src_vocab_size,\n",
    "    max_seq_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'encoder_block' (type EncoderBlock).\n\n{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,30,12] vs. [3,90,12] [Op:AddV2] name: \n\nCall arguments received by layer 'encoder_block' (type EncoderBlock):\n  • x=tf.Tensor(shape=(3, 30, 12), dtype=float32)\n  • training=True\n  • mask=tf.Tensor(shape=(3, 1, 1, 30), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m encoder_output, attn_wieghts \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadded_input_seqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoder Output \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoder_output\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(encoder_output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[24], line 27\u001b[0m, in \u001b[0;36mEncoder.call\u001b[1;34m(self, input, training, mask)\u001b[0m\n\u001b[0;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(token_embeddings \u001b[38;5;241m+\u001b[39m positional_embeddings, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m---> 27\u001b[0m     x, weights \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, weights\n",
      "Cell \u001b[1;32mIn[23], line 19\u001b[0m, in \u001b[0;36mEncoderBlock.call\u001b[1;34m(self, x, training, mask)\u001b[0m\n\u001b[0;32m     17\u001b[0m mhsa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(mhsa_output, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# skip connection\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m mhsa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm1(\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmhsa_output\u001b[49m)\n\u001b[0;32m     21\u001b[0m ffn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(mhsa_output)\n\u001b[0;32m     22\u001b[0m ffn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(ffn_output, trainin\u001b[38;5;241m=\u001b[39mtraining)\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'encoder_block' (type EncoderBlock).\n\n{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,30,12] vs. [3,90,12] [Op:AddV2] name: \n\nCall arguments received by layer 'encoder_block' (type EncoderBlock):\n  • x=tf.Tensor(shape=(3, 30, 12), dtype=float32)\n  • training=True\n  • mask=tf.Tensor(shape=(3, 1, 1, 30), dtype=float32)"
     ]
    }
   ],
   "source": [
    "encoder_output, attn_wieghts = encoder(input=padded_input_seqs, training=True, mask=encoder_mask)\n",
    "\n",
    "print(f\"Encoder Output {encoder_output.shape}:\")\n",
    "print(encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
